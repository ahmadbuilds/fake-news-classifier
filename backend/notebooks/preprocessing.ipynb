{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e093fdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0         REDUX 1963? The Deep State vs Donald Trump   \n",
      "1  CATHERINE ENGELBRECHT: â€œAn Attack On One Right...   \n",
      "2  WATCH VETERAN Embarrass Trump Hater In Kansas ...   \n",
      "3  PENTAGON REQUEST DENIED: [Video] ARMED CITIZEN...   \n",
      "4  U.S. House lawmaker to release revamped Dodd-F...   \n",
      "\n",
      "                                                text          subject  \\\n",
      "0  Patrick Henningsen 21st Century WireWatching t...          US_News   \n",
      "1  This woman is a hero! Catherine Engelbrecht st...  Government News   \n",
      "2  This veteran exposes Trump hating protester in...        left-news   \n",
      "3  Ordinary citizens (many of them are proud vete...  Government News   \n",
      "4  WASHINGTON (Reuters) - The head of the U.S. Ho...     politicsNews   \n",
      "\n",
      "        date  \n",
      "0 2017-01-15  \n",
      "1 2016-04-06  \n",
      "2 2016-03-17  \n",
      "3 2015-07-25  \n",
      "4        NaT  \n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from datetime import datetime\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "# Function to parse dates with mixed formats\n",
    "def parse_mixed_date(x):\n",
    "    for fmt in (\"%b %d, %Y\", \"%B %d, %Y\"):\n",
    "        try:\n",
    "            return datetime.strptime(x, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return pd.NaT\n",
    "\n",
    "\n",
    "# Load the data\n",
    "#Combine the two datasets and shuffle them\n",
    "data1=pd.read_csv('../data/raw/Fake.csv',delimiter=',')\n",
    "data2=pd.read_csv('../data/raw/True.csv',delimiter=',')\n",
    "data1['label']=0\n",
    "data2['label']=1\n",
    "\n",
    "data=pd.concat([data1,data2],ignore_index=True)\n",
    "data=data.sample(frac=1).reset_index(drop=True)\n",
    "data[\"date\"]=data[\"date\"].apply(parse_mixed_date)\n",
    "\n",
    "x_train=data.drop(columns=['label'])\n",
    "y_train=data['label']\n",
    "\n",
    "print(x_train.head())\n",
    "\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7057fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    patrick henningsen  centuri wirewatch  week  s...\n",
      "1     woman   hero  catherin engelbrecht stood    i...\n",
      "2     veteran expos trump hate protest  kansa citi ...\n",
      "3    ordinari citizen  mani    proud veteran   fill...\n",
      "4    washington  reuter    head    hous  repres com...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#preprocessing the text data\n",
    "\n",
    "#Lowering the text\n",
    "x_train['title']=x_train['title'].str.lower()\n",
    "x_train['text']=x_train['text'].str.lower()\n",
    "x_train['subject']=x_train['subject'].str.lower()\n",
    "\n",
    "#tokenization\n",
    "tokenized=[nltk.word_tokenize(i) for i in x_train['text']]\n",
    "\n",
    "#removing stopwords and non-alphabetic characters\n",
    "#stemming the words\n",
    "ps=nltk.PorterStemmer()\n",
    "\n",
    "stopwords=set(stopwords.words('english'))\n",
    "\n",
    "for i in range(len(tokenized)):\n",
    "    tokenized[i]=[word if word.isalpha() else '' for word in tokenized[i]]\n",
    "    tokenized[i]=[word if word not in stopwords else '' for word in tokenized[i] ]\n",
    "    tokenized[i]=[ps.stem(word) if word else '' for word in tokenized[i]]\n",
    "\n",
    "\n",
    "#joining the tokens back to form the text\n",
    "for i in range(len(tokenized)):\n",
    "    tokenized[i]=' '.join(tokenized[i])\n",
    "x_train['text']=tokenized\n",
    "\n",
    "print(x_train['text'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aed31c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the preprocessed data\n",
    "x_train.to_csv('../data/processed/x_train.csv',index=False)\n",
    "y_train.to_csv('../data/processed/y_train.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
