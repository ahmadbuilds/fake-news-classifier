{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e093fdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  ENTITLED IRS ETHICS LAWYER DISBARRED FOR ETHIC...   \n",
      "1  North Korea's Kim says will make 'deranged' Tr...   \n",
      "2   Stephen Colbert And His Audience Absolutely P...   \n",
      "3  Wasserman Schultz will not open Democratic con...   \n",
      "4  TRUMP GIVES BRUTAL WARNING To Lawless Sanctuar...   \n",
      "\n",
      "                                                text       subject       date  \n",
      "0  Don t you just love an entitled IRS lawyer who...     left-news 2015-04-04  \n",
      "1  SEOUL (Reuters) - North Korea s leader Kim Jon...     worldnews        NaT  \n",
      "2  When appearing on The Late Show with Stephen C...          News 2016-02-09  \n",
      "3  WASHINGTON (Reuters) - Democratic National Com...  politicsNews        NaT  \n",
      "4  .@KrisKobach1787: Trump has made clear that sa...      politics 2016-11-15  \n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from datetime import datetime\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "# Function to parse dates with mixed formats\n",
    "def parse_mixed_date(x):\n",
    "    for fmt in (\"%b %d, %Y\", \"%B %d, %Y\"):\n",
    "        try:\n",
    "            return datetime.strptime(x, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return pd.NaT\n",
    "\n",
    "\n",
    "# Load the data\n",
    "#Combine the two datasets and shuffle them\n",
    "data1=pd.read_csv('../data/raw/Fake.csv',delimiter=',')\n",
    "data2=pd.read_csv('../data/raw/True.csv',delimiter=',')\n",
    "data1['label']=0\n",
    "data2['label']=1\n",
    "\n",
    "data=pd.concat([data1,data2],ignore_index=True)\n",
    "data=data.sample(frac=1).reset_index(drop=True)\n",
    "data[\"date\"]=data[\"date\"].apply(parse_mixed_date)\n",
    "\n",
    "x_train=data.drop(columns=['label'])\n",
    "y_train=data['label']\n",
    "\n",
    "print(x_train.head())\n",
    "\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7057fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    love entitl ir lawyer claim fire even better e...\n",
      "1    seoul reuter north korea leader kim jong un sa...\n",
      "2    appear late show stephen colbert probabl best ...\n",
      "3    washington reuter democrat nation committe cha...\n",
      "4    trump made clear sanctuari citi could lose fed...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#preprocessing the text data\n",
    "\n",
    "#Lowering the text\n",
    "x_train['title']=x_train['title'].str.lower()\n",
    "x_train['text']=x_train['text'].str.lower()\n",
    "x_train['subject']=x_train['subject'].str.lower()\n",
    "\n",
    "#tokenization\n",
    "tokenized=[nltk.word_tokenize(i) for i in x_train['text']]\n",
    "\n",
    "#removing stopwords and non-alphabetic characters\n",
    "#stemming the words\n",
    "ps=nltk.PorterStemmer()\n",
    "\n",
    "stopwords=set(stopwords.words('english'))\n",
    "\n",
    "for i in range(len(tokenized)):\n",
    "    tokenized[i]=[word for word in tokenized[i] if word.isalpha()]\n",
    "    tokenized[i]=[word for word in tokenized[i] if word not in stopwords]\n",
    "    tokenized[i]=[ps.stem(word) for word in tokenized[i]]\n",
    "\n",
    "\n",
    "#joining the tokens back to form the text\n",
    "for i in range(len(tokenized)):\n",
    "    tokenized[i]=' '.join(tokenized[i])\n",
    "x_train['text']=tokenized\n",
    "\n",
    "print(x_train['text'].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
