{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e093fdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0   A Panicked Trump Ran Around The White House A...   \n",
      "1   WATCH: Will Ferrell Skewers Trump As He Repri...   \n",
      "2   Watch Heartbreaking Cries From An Abused Pupp...   \n",
      "3  U.S. intel committee subpoenas comedian in Rus...   \n",
      "4  MESSAGE TO THE LEFT ON IMMIGRATION: If You Dis...   \n",
      "\n",
      "                                                text    subject       date  \n",
      "0  This incredibly awkward story comes from New Y...       News 2017-06-30  \n",
      "1  Last night, during the official White House Co...       News 2017-04-30  \n",
      "2  A video of a terrified and previously abused p...       News 2016-01-02  \n",
      "3  (Reuters) - A New York comedian has been compe...  worldnews 2017-11-30  \n",
      "4  IT S A MUST READ! The first month of the Trump...   politics 2017-02-27  \n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from datetime import datetime\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "\n",
    "def parse_date(x):\n",
    "    for fmt in (\"%B %d, %Y\", \"%b %d, %Y\"):\n",
    "        try:\n",
    "            return datetime.strptime(x.strip(), fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "# Load the data\n",
    "#Combine the two datasets and shuffle them\n",
    "data1=pd.read_csv('../data/raw/Fake.csv',delimiter=',')\n",
    "data2=pd.read_csv('../data/raw/True.csv',delimiter=',')\n",
    "data1['label']=0\n",
    "data2['label']=1\n",
    "\n",
    "data=pd.concat([data1,data2],ignore_index=True)\n",
    "data=data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data.loc[data[\"date\"] == \"14-Feb-18\", \"date\"] = \"February 14, 2018\"\n",
    "data.loc[data[\"date\"] == \"15-Feb-18\", \"date\"] = \"February 15, 2018\"\n",
    "data.loc[data[\"date\"] == \"16-Feb-18\", \"date\"] = \"February 16, 2018\"\n",
    "data.loc[data[\"date\"] == \"17-Feb-18\", \"date\"] = \"February 17, 2018\"\n",
    "data.loc[data[\"date\"] == \"18-Feb-18\", \"date\"] = \"February 18, 2018\"\n",
    "data.loc[data[\"date\"] == \"19-Feb-18\", \"date\"] = \"February 19, 2018\"\n",
    "\n",
    "data[\"date\"]=data[\"date\"].apply(parse_date)\n",
    "\n",
    "x_train=data.drop(columns=['label'])\n",
    "y_train=data['label']\n",
    "\n",
    "print(x_train.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7057fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    incred awkward stori come new york post report...\n",
      "1    last night offici white hous correspond dinner...\n",
      "2    video terrifi previous abus puppi shown love f...\n",
      "3    reuter new york comedian compel appear hous in...\n",
      "4    must read first month trump administr alreadi ...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#preprocessing the text data\n",
    "\n",
    "#filling missing values\n",
    "x_train['title']=x_train['title'].fillna('')\n",
    "\n",
    "x_train['text']=x_train['text'].fillna('')\n",
    "\n",
    "x_train['subject']=x_train['subject'].fillna('')\n",
    "\n",
    "x_train['date']=x_train['date'].ffill()\n",
    "\n",
    "\n",
    "#Lowering the text\n",
    "x_train['title']=x_train['title'].str.lower()\n",
    "x_train['text']=x_train['text'].str.lower()\n",
    "x_train['subject']=x_train['subject'].str.lower()\n",
    "\n",
    "#tokenization\n",
    "tokenized=[nltk.word_tokenize(i) for i in x_train['text']]\n",
    "\n",
    "#removing stopwords and non-alphabetic characters\n",
    "#stemming the words\n",
    "ps=nltk.PorterStemmer()\n",
    "\n",
    "stopwords=set(stopwords.words('english'))\n",
    "\n",
    "for i in range(len(tokenized)):\n",
    "    # Keep only alphabetic words and remove stopwords\n",
    "    tokenized[i] = [ps.stem(word) for word in tokenized[i] if word.isalpha() and word not in stopwords]\n",
    "\n",
    "    tokenized[i] = ' '.join(tokenized[i]) if tokenized[i] else ' '\n",
    "\n",
    "\n",
    "x_train['text'] = tokenized\n",
    "\n",
    "print(x_train['text'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aed31c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the preprocessed data\n",
    "x_train.to_csv('../data/processed/x_train.csv',index=False)\n",
    "y_train.to_csv('../data/processed/y_train.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
